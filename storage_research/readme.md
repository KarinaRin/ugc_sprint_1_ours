# Исследование: выбор хранилища
**Задача проекта** - сохранить метки данных о просмотрах фильмов из приложения в аналитическое хранилище.
  
**Цель исследования** - протестировать работоспособность схемы хранения и обработки данных, применительно на этой задаче

## 1. Подготовка кластера хранилища для работы  

- скачать папку storage_research и установить зависимости
- `docker-compose up -d` - поднять базы Clickhouse и Vertica
 
## 2. Загрузка или генерация первоначальных данных

- запустите по очереди скрипты clickhouse.py и vertica.py  

Вставка данных производится пачками по 10 тыс.записей.
В результате хранилища будут заполнены **10 млн.** сгенерированных данных. 
Предполагается (_в целях задачи)_, 1 млн. пользователей и 10000 фильмов.

## 3. Тестирование обработки данных, поступающих в реальном времени

Уже на предыдущей стадии было отмечено преимущество Clichhouse - загрузка 10 млн. записей прошла за 40 секунд.
Vertika справилась за 145 сек, т.е. в 3,5 раза медленней. 
Хотя оба результата могут считать превосходными.

Для запуска тестов вставки необходимо в папке test_results запустить скрипты (очередность важна!):
сначала `insert_test_clickhouse.py`, а затем `insert_test_vertica.py`  

Посмотрим на полученную сравнительную таблицу (файл `insert_test.csv`):  

|-------|------------|---------|
| chunk | clickhouse | vertica |
|-------|------------|---------|
|   10  |     0.0013 |  0.0529 |
+-------+------------+---------+
|  100  |     0.0016 |  0.0541 |
+-------+------------+---------+
|  200  |     0.0019 |  0.0588 |
+-------+------------+---------+
|  500  |     0.0033 |  0.0394 |
+-------+------------+---------+
|  700  |     0.0046 |  0.0262 |
+-------+------------+---------+
|  1000 |     0.0050 |  0.0643 |
+-------+------------+---------+
|  1500 |     0.0066 |  0.0677 |
+-------+------------+---------+
|  2000 |     0.0092 |  0.0634 |
+-------+------------+---------+
|  3000 |     0.0124 |  0.0713 |
+-------+------------+---------+
|  4000 |     0.0207 |  0.0893 |
+-------+------------+---------+
|  5000 |     0.0179 |  0.0790 |
+-------+------------+---------+
|  6000 |     0.0237 |  0.0979 |
+-------+------------+---------+
|  8000 |     0.0323 |  0.1033 |
+-------+------------+---------+
| 10000 |     0.0372 |  0.1190 |
+-------+------------+---------+

Мы видим, что любая величина пакета данных в Vertica загружается меделенней. От 2 до 10 раз!  
Следует отметить, что несмотря на то, что данные приводятся усредненные после выборки из 10 повторений по каждому типу пакета данных, 
при повторении теста разброс данных внутри каждого хранилища достигал порой 50%. 
Возможно выборку надо проводить на большем числе повторов, но это приводит к другой проблеме - сопоставимости результатов относительно исходной базы.
Ведь каждый тест увеличивает количество записей.

Ниже представлены данные победителя - хранилища Clickhouse:

![img.png](img.png)

Зависимость времени загрузки пакета от его размерности прослеживается довольно четко.  
Но можно ли ответить на вопрос: "Какой пакет вставки данных будет наиболее эффективным?"  
Если взять за критерий эффективности теоретическую скорость вставки одной записи в пакете, то увидим следующий результат:

![img_1.png](img_1.png)

Удивительно, но, начиная с пакета данных в 1000 записей, 
колебания конечного результата можно считать не столь существенными. 
Лучший результат - у пакета на 300 записей. Однако, пакет в 10000 записей 
не ушел от него далеко в плане эффективности.  
Если возникает ощутимый простой между донаборами нужного количества записей в пакет, 
то можно уменьшить пакет до 700, 500 и даже до 200 записей. 
Это не будет столь критично, судя по результатам.

## 4. Тестирование обработки уже загруженных данных
Была протестирована обработка данных в хранилище. 
Для этого запустим скрипты (очередность важна): `select_test_clickhouse.py` и `select_test_vertica.py`
Запросы какого характера формировались можно посмотреть внутри скриптов.

+------------+---------+------------------------------------------------------------------+
| Clickhouse | Vertica | Описание запроса                                                 |
+------------+---------+------------------------------------------------------------------+
| 0.0029     | 0.0077  | Список всех фильмов @юзера                                       |
+------------+---------+------------------------------------------------------------------+
| 0.0036     | 0.0072  | Все фильмы @юзера (+ лучший тайминг)                             |
+------------+---------+------------------------------------------------------------------+
| 0.0039     | 0.0071  | Самый долгий просмотра @фильма @юзером                           |
+------------+---------+------------------------------------------------------------------+
| 0.1790     | 0.0869  | Список юзеров смотревших @фильм                                  |
+------------+---------+------------------------------------------------------------------+
| 0.0012     | 0.0106  | Сколько всего записей                                            |
+------------+---------+------------------------------------------------------------------+
| 0.1904     | 0.6636  | Средний тайминг просмотра каждого фильма                         |
+------------+---------+------------------------------------------------------------------+
| 1.9561     | 2.8324  | Список всех фильмов по разу                                      |
+------------+---------+------------------------------------------------------------------+
| 2.3973     | 3.3476  | Количество фильмов запущенных хоть раз на просмотр каждым юзером |
+------------+---------+------------------------------------------------------------------+

Здесь также мы видим тотальное преимущество Clickhouse, хотя и не столь значительное - редко когда больше двукратного.

# Выводы
**Clickhouse показал себя более производительной СУБД, в качестве OLAP-хранилища**